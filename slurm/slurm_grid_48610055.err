+ PROJECT_ROOT=/scratch/pbm52/emotion-detection-mm/multimodal-emotion-detection
+ GRID_ROOT=/scratch/pbm52/emotion-detection-mm/multimodal-emotion-detection/grid_sweep_results
+ mkdir -p /scratch/pbm52/emotion-detection-mm/multimodal-emotion-detection/slurm
+ mkdir -p /scratch/pbm52/emotion-detection-mm/multimodal-emotion-detection/grid_sweep_results
+ LRS=(0.0005 0.001 0.002)
+ MODEL_DROPS=(0.0 0.1)
+ MODALITY_DROPS=(0.0 0.05)
+ module purge
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_sh_dbg=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for Lmod's output
Shell debugging restarted
+ unset __lmod_sh_dbg
+ return 0
+ module use /projects/community/modulefiles
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_sh_dbg=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for Lmod's output
Shell debugging restarted
+ unset __lmod_sh_dbg
+ return 0
+ module load gcc/10.2.0/openmpi
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_sh_dbg=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for Lmod's output
Shell debugging restarted
+ unset __lmod_sh_dbg
+ return 0
+ module load cuda/12.1
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_sh_dbg=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for Lmod's output
Shell debugging restarted
+ unset __lmod_sh_dbg
+ return 0
+ cd /scratch/pbm52/emotion-detection-mm/multimodal-emotion-detection
+ '[' '!' -d .venv ']'
+ source .venv/bin/activate
++ '[' -z '' ']'
++ '[' -n x ']'
++ SCRIPT_PATH=.venv/bin/activate
++ '[' .venv/bin/activate = /var/lib/slurm/slurmd/job48610055/slurm_script ']'
++ deactivate nondestructive
++ unset -f pydoc
++ '[' -z '' ']'
++ '[' -z '' ']'
++ hash -r
++ '[' -z '' ']'
++ unset VIRTUAL_ENV
++ unset VIRTUAL_ENV_PROMPT
++ '[' '!' nondestructive = nondestructive ']'
++ VIRTUAL_ENV=/scratch/pbm52/emotion-detection-mm/multimodal-emotion-detection/.venv
++ '[' linux-gnu = cygwin ']'
++ '[' linux-gnu = msys ']'
++ export VIRTUAL_ENV
++ '[' -z '' ']'
++ unset SCRIPT_PATH
++ _OLD_VIRTUAL_PATH=/opt/sw/packages/cuda/12.1.0/bin:/projects/community/gcc/10.2.0/openmpi/4.0.5/bz186/bin:/projects/community/gcc/10.2.0/bz186/bin:/home/pbm52/.local/bin:/projects/community/anaconda/2020.07/gc563/bin:/usr/lpp/mmfs/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/pbm52/bin
++ PATH=/scratch/pbm52/emotion-detection-mm/multimodal-emotion-detection/.venv/bin:/opt/sw/packages/cuda/12.1.0/bin:/projects/community/gcc/10.2.0/openmpi/4.0.5/bz186/bin:/projects/community/gcc/10.2.0/bz186/bin:/home/pbm52/.local/bin:/projects/community/anaconda/2020.07/gc563/bin:/usr/lpp/mmfs/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/pbm52/bin
++ export PATH
++ '[' xmultimodal-emotion-detection '!=' x ']'
++ VIRTUAL_ENV_PROMPT=multimodal-emotion-detection
++ export VIRTUAL_ENV_PROMPT
++ '[' -z '' ']'
++ '[' -z '' ']'
++ _OLD_VIRTUAL_PS1=
++ PS1='(multimodal-emotion-detection) '
++ export PS1
++ alias pydoc
++ true
++ hash -r
+ echo 'Syncing environment with uv...'
+ uv sync
Resolved 157 packages in 3ms
Audited 148 packages in 1.85s
++ uv run python -c 'import certifi; print(certifi.where())'
+ export SSL_CERT_FILE=/scache/scratch/pbm52/emotion-detection-mm/multimodal-emotion-detection/.venv/lib/python3.10/site-packages/certifi/cacert.pem
+ SSL_CERT_FILE=/scache/scratch/pbm52/emotion-detection-mm/multimodal-emotion-detection/.venv/lib/python3.10/site-packages/certifi/cacert.pem
+ export RAVDESS_DATA_ROOT=/scratch/pbm52/emotion-detection-mm/multimodal-dataset
+ RAVDESS_DATA_ROOT=/scratch/pbm52/emotion-detection-mm/multimodal-dataset
+ export PYTHONPATH=:src
+ PYTHONPATH=:src
+ export CUDA_VISIBLE_DEVICES=0
+ CUDA_VISIBLE_DEVICES=0
+ echo 'Job ID:          48610055'
+ echo 'Node:            gpuk003'
+ echo 'GPU:             0'
++ pwd
+ echo 'Working Dir:     /scratch/pbm52/emotion-detection-mm/multimodal-emotion-detection'
+ echo 'RAVDESS Root:    /scratch/pbm52/emotion-detection-mm/multimodal-dataset'
+ nvidia-smi
+ for LR in '"${LRS[@]}"'
+ for MDROP in '"${MODALITY_DROPS[@]}"'
+ for MD in '"${MODEL_DROPS[@]}"'
+ LR_TAG=0p0005
+ MD_TAG=0p0
+ MMD_TAG=0p0
+ TAG=lr0p0005_drop0p0_mDrop0p0
+ EXP_NAME=ravdess_sweep_lr0p0005_drop0p0_mDrop0p0
+ echo ============================================================
+ echo 'Starting sweep run: lr0p0005_drop0p0_mDrop0p0'
+ echo '  LR               = 0.0005'
+ echo '  model.dropout    = 0.0'
+ echo '  modality_dropout = 0.0'
+ echo '  experiment.name  = ravdess_sweep_lr0p0005_drop0p0_mDrop0p0'
+ echo ============================================================
+ uv run python src/train.py experiment.name=ravdess_sweep_lr0p0005_drop0p0_mDrop0p0 dataset.name=ravdess dataset.data_dir=/scratch/pbm52/emotion-detection-mm/multimodal-dataset 'dataset.modalities=[audio, video]' dataset.num_classes=8 model.output_dim=256 model.hidden_dim=512 model.dropout=0.0 model.encoders.audio.hidden_dim=512 model.encoders.audio.output_dim=256 model.encoders.audio.num_layers=3 model.encoders.audio.dropout=0.1 model.encoders.video.hidden_dim=512 model.encoders.video.output_dim=256 model.encoders.video.dropout=0.1 training.max_epochs=80 training.early_stopping_patience=15 training.learning_rate=0.0005 training.augmentation.modality_dropout=0.0
/scache/scratch/pbm52/emotion-detection-mm/multimodal-emotion-detection/.venv/lib/python3.10/site-packages/lightning_fabric/__init__.py:36: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  __import__("pkg_resources").declare_namespace(__name__)
[rank: 0] Global seed set to 42
/scache/scratch/pbm52/emotion-detection-mm/multimodal-emotion-detection/.venv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 src/train.py experiment.name=ravdess_sweep_lr0p0005 ...
  rank_zero_warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/scache/scratch/pbm52/emotion-detection-mm/multimodal-emotion-detection/.venv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 src/train.py experiment.name=ravdess_sweep_lr0p0005 ...
  rank_zero_warn(
You are using a CUDA device ('NVIDIA A100-PCIE-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
Missing logger folder: outputs/ravdess_sweep_lr0p0005_drop0p0_mDrop0p0/tb_logs
Error executing job with overrides: ['experiment.name=ravdess_sweep_lr0p0005_drop0p0_mDrop0p0', 'dataset.name=ravdess', 'dataset.data_dir=/scratch/pbm52/emotion-detection-mm/multimodal-dataset', 'dataset.modalities=[audio, video]', 'dataset.num_classes=8', 'model.output_dim=256', 'model.hidden_dim=512', 'model.dropout=0.0', 'model.encoders.audio.hidden_dim=512', 'model.encoders.audio.output_dim=256', 'model.encoders.audio.num_layers=3', 'model.encoders.audio.dropout=0.1', 'model.encoders.video.hidden_dim=512', 'model.encoders.video.output_dim=256', 'model.encoders.video.dropout=0.1', 'training.max_epochs=80', 'training.early_stopping_patience=15', 'training.learning_rate=0.0005', 'training.augmentation.modality_dropout=0.0']
Traceback (most recent call last):
  File "/scache/scratch/pbm52/emotion-detection-mm/multimodal-emotion-detection/src/train.py", line 547, in main
    trainer.fit(model, train_loader, val_loader)
  File "/scache/scratch/pbm52/emotion-detection-mm/multimodal-emotion-detection/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 531, in fit
    call._call_and_handle_interrupt(
  File "/scache/scratch/pbm52/emotion-detection-mm/multimodal-emotion-detection/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/scache/scratch/pbm52/emotion-detection-mm/multimodal-emotion-detection/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 570, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/scache/scratch/pbm52/emotion-detection-mm/multimodal-emotion-detection/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 951, in _run
    self.strategy.setup(self)
  File "/scache/scratch/pbm52/emotion-detection-mm/multimodal-emotion-detection/.venv/lib/python3.10/site-packages/pytorch_lightning/strategies/single_device.py", line 74, in setup
    self.model_to_device()
  File "/scache/scratch/pbm52/emotion-detection-mm/multimodal-emotion-detection/.venv/lib/python3.10/site-packages/pytorch_lightning/strategies/single_device.py", line 71, in model_to_device
    self.model.to(self.root_device)
  File "/scache/scratch/pbm52/emotion-detection-mm/multimodal-emotion-detection/.venv/lib/python3.10/site-packages/lightning_fabric/utilities/device_dtype_mixin.py", line 54, in to
    return super().to(*args, **kwargs)
  File "/scache/scratch/pbm52/emotion-detection-mm/multimodal-emotion-detection/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1145, in to
    return self._apply(convert)
  File "/scache/scratch/pbm52/emotion-detection-mm/multimodal-emotion-detection/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 797, in _apply
    module._apply(fn)
  File "/scache/scratch/pbm52/emotion-detection-mm/multimodal-emotion-detection/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 797, in _apply
    module._apply(fn)
  File "/scache/scratch/pbm52/emotion-detection-mm/multimodal-emotion-detection/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 797, in _apply
    module._apply(fn)
  File "/scache/scratch/pbm52/emotion-detection-mm/multimodal-emotion-detection/.venv/lib/python3.10/site-packages/torch/nn/modules/rnn.py", line 197, in _apply
    ret = super()._apply(fn)
  File "/scache/scratch/pbm52/emotion-detection-mm/multimodal-emotion-detection/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 820, in _apply
    param_applied = fn(param)
  File "/scache/scratch/pbm52/emotion-detection-mm/multimodal-emotion-detection/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
